{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Speech recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pip install SpeechRecognition  \n",
    "Need also to install pyAudio  \n",
    "Other instructions here http://people.csail.mit.edu/hubert/pyaudio/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NB: I had some troubles to install pyAudio on Ubuntu. To make it work properly use the command below:  \n",
    "sudo apt-get install portaudio19-dev python-pyaudio\n",
    "pip install pyAudio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.codinground.com/speech-recognition/  \n",
    "https://github.com/Uberi/speech_recognition/blob/master/examples/microphone_recognition.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import speech_recognition as sr\n",
    "import wave\n",
    "import pyaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = sr.Recognizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['HDA Intel HDMI: 0 (hw:0,3)',\n",
       " 'HDA Intel HDMI: 1 (hw:0,7)',\n",
       " 'HDA Intel HDMI: 2 (hw:0,8)',\n",
       " 'HDA Intel HDMI: 3 (hw:0,9)',\n",
       " 'HDA Intel HDMI: 4 (hw:0,10)',\n",
       " 'HDA Intel PCH: ALC3232 Analog (hw:1,0)',\n",
       " 'HDA NVidia: HDMI 0 (hw:2,3)',\n",
       " 'HDA NVidia: HDMI 1 (hw:2,7)',\n",
       " 'HDA NVidia: HDMI 2 (hw:2,8)',\n",
       " 'HDA NVidia: HDMI 3 (hw:2,9)',\n",
       " 'hdmi',\n",
       " 'pulse',\n",
       " 'default']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sr.Microphone.list_microphone_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "micro = sr.Microphone(device_index=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speak!\n",
      "End!\n",
      "> associate tester\n"
     ]
    }
   ],
   "source": [
    "with micro as source:\n",
    "    print(\"Speak!\")\n",
    "    audio_data = r.listen(source)\n",
    "    print(\"End!\")\n",
    "result = r.recognize_google(audio_data)\n",
    "print (\">\", result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recording from micro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recording\n",
      "Finished recording\n"
     ]
    }
   ],
   "source": [
    "import pyaudio\n",
    "import wave\n",
    "\n",
    "chunk = 1024  # Record in chunks of 1024 samples\n",
    "sample_format = pyaudio.paInt16  # 16 bits per sample\n",
    "channels = 2\n",
    "fs = 44100  # Record at 44100 samples per second\n",
    "seconds = 10\n",
    "filename = \"output.wav\"\n",
    "\n",
    "p = pyaudio.PyAudio()  # Create an interface to PortAudio\n",
    "\n",
    "print('Start Recording ...')\n",
    "\n",
    "stream = p.open(format=sample_format,\n",
    "                channels=channels,\n",
    "                rate=fs,\n",
    "                frames_per_buffer=chunk,\n",
    "                input=True)\n",
    "\n",
    "frames = []  # Initialize array to store frames\n",
    "\n",
    "# Store data in chunks for 3 seconds\n",
    "for i in range(0, int(fs / chunk * seconds)):\n",
    "    data = stream.read(chunk)\n",
    "    frames.append(data)\n",
    "\n",
    "# Stop and close the stream \n",
    "stream.stop_stream()\n",
    "stream.close()\n",
    "# Terminate the PortAudio interface\n",
    "p.terminate()\n",
    "\n",
    "print('... Finished recording')\n",
    "\n",
    "# Save the recorded data as a WAV file\n",
    "wf = wave.open(filename, 'wb')\n",
    "wf.setnchannels(channels)\n",
    "wf.setsampwidth(p.get_sample_size(sample_format))\n",
    "wf.setframerate(fs)\n",
    "wf.writeframes(b''.join(frames))\n",
    "wf.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting the analyzed results with Google Speech recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Histoire commence un beau matin tout le monde va bien les élèves sont heureux\n"
     ]
    }
   ],
   "source": [
    "import speech_recognition as sr\n",
    "r = sr.Recognizer()\n",
    "\n",
    "with sr.AudioFile(filename) as source:\n",
    "\n",
    "    audio = r.record(source)\n",
    "    try:\n",
    "        # data = r.recognize_google(audio)\n",
    "        data = r.recognize_google(audio, language=\"fr-FR\")\n",
    "        print(data)\n",
    "    except:\n",
    "        print(\"Please try again\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# With CMUSphinx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://cmusphinx.github.io/wiki/  \n",
    "https://pypi.org/project/pocketsphinx/  \n",
    "https://doc.ubuntu-fr.org/pocketsphinx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* recording\n",
      "312.5 size\n",
      "\n",
      "* done recording\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'hmm'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-57b3c6a53d1b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0mwf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0mwavfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m     \u001b[0mrecognised\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecodeSpeech\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhmdir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlmd\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdictd\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwavfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m     \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mrecognised\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mcm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'espeak \"'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mrecognised\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'\"'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-17-57b3c6a53d1b>\u001b[0m in \u001b[0;36mdecodeSpeech\u001b[0;34m(hmmd, lmdir, dictp, wavfile)\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mimport\u001b[0m \u001b[0msphinxbase\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mspeechRec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mps\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhmm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhmmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlmdir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdictp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0mwavFile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwavfile\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mwavFile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseek\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m44\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'hmm'"
     ]
    }
   ],
   "source": [
    "import sys,os\n",
    "import pyaudio\n",
    "import wave\n",
    "\n",
    "hmdir = \"/usr/share/pocketsphinx/model/FR/\"\n",
    "lmd = \"/usr/share/pocketsphinx/model/FR/french3g62K.lm.dmp\"\n",
    "dictd = \"/usr/share/pocketsphinx/model/FR/frenchWords62K.dic\"\n",
    " \n",
    "def decodeSpeech(hmmd,lmdir,dictp,wavfile):\n",
    "    import pocketsphinx as ps\n",
    "    import sphinxbase\n",
    " \n",
    "    speechRec = ps.Decoder(hmm = hmmd, lm = lmdir, dict = dictp)\n",
    "    wavFile = file(wavfile,'rb')\n",
    "    wavFile.seek(44)\n",
    "    speechRec.decode_raw(wavFile)\n",
    "    result = speechRec.get_hyp()\n",
    " \n",
    "    return result[0]\n",
    " \n",
    "#CHUNK = 1024\n",
    "CHUNK = 512\n",
    "#FORMAT = pyaudio.paInt16\n",
    "FORMAT = pyaudio.paALSA\n",
    "CHANNELS = 1\n",
    "RATE = 16000\n",
    "#RATE = 44100\n",
    "RECORD_SECONDS = 10\n",
    " \n",
    "for x in range(10):\n",
    "    fn = \"o\"+str(x)+\".wav\"\n",
    "    p = pyaudio.PyAudio()\n",
    "    stream = p.open(format=FORMAT, channels=CHANNELS, rate=RATE, input=True, frames_per_buffer=CHUNK)\n",
    "    print(\"* recording\")\n",
    "    frames = []\n",
    "    print(str(RATE / CHUNK * RECORD_SECONDS) + \" size\\n\")\n",
    "    for i in range(0, int(RATE / CHUNK * RECORD_SECONDS)):\n",
    "        data = stream.read(CHUNK)\n",
    "        frames.append(data)\n",
    "    print(\"* done recording\")\n",
    "    stream.stop_stream()\n",
    "    stream.close()\n",
    "    wf = wave.open(fn, 'wb')\n",
    "    wf.setnchannels(CHANNELS)\n",
    "    wf.setsampwidth(p.get_sample_size(FORMAT))\n",
    "    p.terminate()\n",
    "    wf.setframerate(RATE)\n",
    "    wf.writeframes(b''.join(frames))\n",
    "    wf.close()\n",
    "    wavfile = fn\n",
    "    recognised = decodeSpeech(hmdir,lmd,dictd,wavfile)\n",
    "    print (recognised)\n",
    "    cm = 'espeak \"'+recognised+'\"'\n",
    "    os.system(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
